{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TRIX AR/VR Interactive System","text":"<p>Welcome to the official documentation of our AR/VR project.</p>"},{"location":"#project-overview","title":"Project Overview","text":"<p>This project focuses on building a hybrid AR system using:</p> <ul> <li>QR Code based retrieval</li> <li>SLAM surface detection</li> <li>3D object rendering</li> </ul>"},{"location":"roles/","title":"Roles","text":""},{"location":"roles/#authors","title":"Authors","text":"<ul> <li>Akarsh</li> <li>Suhani</li> <li>Srishti</li> </ul>"},{"location":"blog/","title":"Blog","text":"<p>Welcome to the Trix AR/VR Blog! Here you'll find articles, tutorials, and project updates from our team and community contributors. Explore our latest posts, learn from hands-on guides, and discover innovative ideas in the world of Augmented and Virtual Reality.</p>"},{"location":"blog/#latest-posts","title":"Latest Posts","text":"<ul> <li> <p>Getting Started with AR/VR     A beginner's guide to understanding the basics of AR and VR technologies.</p> </li> <li> <p>Project Showcases     Highlights of our recent AR/VR projects, including demos and technical deep-dives.</p> </li> <li> <p>Team Insights     Personal stories, lessons learned, and tips from our contributors.</p> </li> <li> <p>Tutorials &amp; How-Tos     Step-by-step guides to help you build your own AR/VR experiences.</p> </li> </ul>"},{"location":"blog/#contribute","title":"Contribute","text":"<p>Want to share your own work or insights and join our growing community of creators! We welcome tutorials, project showcases, technical deep-dives, and personal stories related to AR and VR. Your contribution can help others learn and inspire new ideas in the field.</p> <p>Browse the posts below or use the navigation to find topics that interest you. Happy exploring!</p>"},{"location":"blog/2026-02-08-from-idea-to-structure/","title":"From Idea to Structure: Understanding What We Actually Built","text":"<p>Author: Suhani Garg Tags: AR, VR  </p>"},{"location":"blog/2026-02-08-from-idea-to-structure/#background-context","title":"Background Context","text":"<p>When we first proposed building an augmented reality\u2013based menu system, the idea felt exciting and practical. The core concept was simple: scan a menu, display a 3D pizza in AR, and enhance the ordering experience. It seemed modern, interactive, and relevant to real-world use.</p> <p> </p> <p>However, during our initial presentation, we realized that having a good idea is not the same as having a well-defined system. While the motivation behind the project was understood, several important structural questions were raised. These questions helped us recognize that we had explained what we wanted to build, but not clearly enough how it would function.</p>"},{"location":"blog/2026-02-08-from-idea-to-structure/#discussion-and-key-questions-raised","title":"Discussion and Key Questions Raised","text":"<p>During the discussion, one of the main concerns was about marker usage.</p> <p>It was unclear whether:</p> <ul> <li>A single marker would represent the entire menu  </li> <li>Multiple markers would be used for different items  </li> </ul> <p> </p> <p>This created ambiguity about how the system would scale and function in practice.</p> <p>Another important question was:</p> <p>\u201cAfter scanning the marker, what exactly opens?\u201d</p> <p>We had not clearly defined:</p> <ul> <li>Whether a new scene would load  </li> <li>How navigation between items would work  </li> <li>Whether rescanning would be required for each item  </li> </ul> <p>These questions revealed that our explanation lacked system-level clarity.</p>"},{"location":"blog/2026-02-08-from-idea-to-structure/#realizations-from-the-feedback","title":"Realizations from the Feedback","text":"<p>The biggest realization from Day 1 was that a project must be explained as a complete interaction flow, not just a list of features.</p> <p>We understood that evaluators are assessing:</p> <ul> <li>Clarity of system behavior  </li> <li>Correct identification of AR type  </li> <li>Logical scene structure  </li> <li>Realistic scope and implementation  </li> </ul> <p>Without defining marker behavior and scene persistence, the project risked appearing like a basic \u201cscan-and-show\u201d AR demo, even if additional features were planned.</p>"},{"location":"blog/2026-02-08-from-idea-to-structure/#structural-decisions-taken","title":"Structural Decisions Taken","text":"<p>Based on the feedback, we refined the structure of the project before moving forward.</p> <p>The following decisions were made:</p> <ul> <li>The system will use a single marker (menu card or QR image).</li> <li>Scanning the marker will open one persistent AR scene.</li> <li>All interactions will occur within that same scene.</li> <li>Navigation between pizzas will happen using left and right arrows.</li> <li>Ingredient details and nutrition toggles will function inside the same AR environment.</li> </ul> <p>By defining this clearly, the project shifted from a conceptual AR idea to a structured interactive system.</p>"},{"location":"blog/2026-02-08-from-idea-to-structure/#key-learning-from-day-1","title":"Key Learning from Day 1","text":"<p>Day 1 taught us that clarity is more important than complexity. Even a technically simple AR system can be strong if the interaction flow is clearly defined and logically structured.</p> <p>The most important takeaway was:</p> <p>Before building features, define the structure.</p> <p>This reflection helped us move from idea-stage thinking to system-level planning.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/","title":"\ud83c\udf55 Interactive Marker-Based AR Pizza Menu System","text":"<p>Author: Srishti Garg Date: February 15, 2026  </p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#project-overview","title":"\ud83d\udccc Project Overview","text":"<p>The Interactive Marker-Based AR Pizza Menu System is an augmented reality application designed to enhance traditional restaurant menus using immersive 3D visualization.</p> <p> </p> <p>Instead of relying on text descriptions and small images, this system allows users to:</p> <ul> <li>Scan a printed menu  </li> <li>View realistic 3D pizza models  </li> <li>Interact with ingredients  </li> <li>Check nutrition information  </li> <li>Compare portion sizes visually  </li> </ul> <p>The goal is simple: Move from reading about food to experiencing food visually before ordering.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#motivation","title":"\ud83c\udfaf Motivation","text":"<p>Imagine walking into a caf\u00e9 you\u2019ve never visited before.</p> <p>You look at the menu and see names like: Italian Supreme, BBQ Chicken, Veg Delight.</p> <p>But you still don\u2019t know:</p> <ul> <li>What exactly is inside?  </li> <li>How big is medium?  </li> <li>Is it spicy?  </li> </ul> <p>You ask the waiter. They explain. You ask again. They gesture with their hands.</p> <p>This repeated back-and-forth slows ordering and still doesn\u2019t provide a clear visual understanding.</p> <p>Our AR system eliminates this confusion.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#system-demonstration","title":"\ud83d\udcf1 System Demonstration","text":"<p>With a single scan:</p> <ul> <li>A 3D pizza appears on the table  </li> <li>Users switch between pizza varieties using arrows  </li> <li>Portion size scales visually (Small / Medium / Large)  </li> <li>Toppings are tappable  </li> <li>Nutrition details can be toggled  </li> </ul> <p>No repeated scanning. No guessing. No unnecessary questions.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#system-architecture","title":"\ud83c\udfd7 System Architecture","text":""},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#marker-based-ar-model","title":"\ud83d\udd39 Marker-Based AR Model","text":"<p>This project uses marker-based augmented reality.</p> Component Responsibility Printed Menu Acts as AR Marker Camera Feed Detects marker Unity Engine Renders 3D Pizza UI Controls Handles interaction <p>The pizza model is anchored directly to the detected marker, creating a stable AR environment.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#system-flow","title":"\ud83d\udd04 System Flow","text":""},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#step-1-marker-detection","title":"Step 1 \u2014 Marker Detection","text":"<p>The smartphone camera detects the printed menu marker.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#step-2-scene-initialization","title":"Step 2 \u2014 Scene Initialization","text":"<p>A single AR scene is created and anchored.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#step-3-3d-pizza-rendering","title":"Step 3 \u2014 3D Pizza Rendering","text":"<p>A default pizza model appears.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#step-4-interaction","title":"Step 4 \u2014 Interaction","text":"<p>Users can:</p> <ul> <li>Navigate between pizzas  </li> <li>Change portion size  </li> <li>Tap toppings to view ingredient details  </li> <li>Toggle nutrition information (calories &amp; food category)</li> </ul>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#key-features","title":"\ud83e\udde9 Key Features","text":""},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#arrow-based-navigation","title":"\u27a4 Arrow-Based Navigation","text":"<p>Switch between 5\u20138 predefined pizza varieties without rescanning.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#portion-size-visualization","title":"\u27a4 Portion Size Visualization","text":"<p>The 3D model scales dynamically to represent Small, Medium, or Large.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#ingredient-level-interaction","title":"\u27a4 Ingredient-Level Interaction","text":"<p>Each topping is interactive. Selecting it displays its name and description.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#nutrition-toggle","title":"\u27a4 Nutrition Toggle","text":"<p>Users can view calorie details and basic health-related information.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#project-scope","title":"\ud83d\udccf Project Scope","text":"<p>The system is intentionally limited to pizza only.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#included","title":"Included:","text":"<ul> <li>5\u20138 pizza varieties  </li> <li>Static 3D models  </li> <li>Ingredient highlighting  </li> <li>Nutrition information  </li> <li>Single-marker architecture  </li> </ul>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#not-included","title":"Not Included:","text":"<ul> <li>Online ordering  </li> <li>Payment integration  </li> <li>AI recommendations  </li> <li>Real-time customization  </li> <li>Cloud backend  </li> </ul> <p>This focused scope ensures clarity, stability, and feasibility within an academic environment.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#technology-stack","title":"\ud83d\udee0 Technology Stack","text":"<p>The system is developed using:</p> <ul> <li>Unity 3D  </li> <li>AR Foundation  </li> <li>Vuforia SDK  </li> <li>Marker-Based AR  </li> <li>3D Pizza Models  </li> <li>Android Smartphone Deployment  </li> </ul> <p>The application is currently implemented on Android for ease of testing and deployment but can be extended to iOS.</p>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#technical-components-used","title":"\ud83e\udde0 Technical Components Used","text":"<ul> <li>Computer Vision  </li> <li>Feature Detection Algorithms  </li> <li>Marker Tracking  </li> <li>Pose Estimation  </li> <li>3D Rendering  </li> <li>UI Integration in AR Space  </li> </ul>"},{"location":"blog/2026-02-09-Interactive-Marker-Based-AR-Pizza-Menu-System/#expected-outcome","title":"\ud83d\ude80 Expected Outcome","text":"<p>This project demonstrates how augmented reality can transform a static menu into an interactive decision-making tool.</p> <p>It enhances:</p> <ul> <li>User confidence  </li> <li>Ordering speed  </li> <li>Visual clarity  </li> <li>Informational transparency  </li> </ul> <p>Rather than being a novelty feature, the AR system functions as a meaningful interface that improves everyday experiences like restaurant ordering.</p>"},{"location":"blog/2026-02-13-system-flow/","title":"\ud83c\udf55 Hybrid Augmented Reality (AR) Pizza Visualization System","text":"<p>Author: Akarsh Date: February 13, 2026  </p>"},{"location":"blog/2026-02-13-system-flow/#project-overview","title":"\ud83d\udccc Project Overview","text":"<p>This project presents a Hybrid Augmented Reality (AR) system that combines:</p> <ul> <li>QR Code-based Data Retrieval</li> <li>SLAM-based Surface Detection</li> <li>3D Object Placement on Real-world Tables</li> </ul> <p>Unlike traditional marker-based AR systems, this architecture separates:</p> <ul> <li>QR Code \u2192 Data Trigger</li> <li>SLAM \u2192 Real-world Surface Placement</li> </ul> <p>This enables a more immersive and technically advanced AR experience.</p>"},{"location":"blog/2026-02-13-system-flow/#system-capabilities","title":"\ud83c\udfaf System Capabilities","text":"<p>The system allows users to:</p> <ol> <li>Scan a QR code on a restaurant menu.</li> <li>Load the complete pizza menu dynamically.</li> <li>Select a specific pizza.</li> <li>View a 3D pizza model rendered on the real table in front of them.</li> </ol>"},{"location":"blog/2026-02-13-system-flow/#architecture-overview","title":"\ud83e\udde0 Architecture Overview","text":""},{"location":"blog/2026-02-13-system-flow/#hybrid-model","title":"\ud83d\udd39 Hybrid Model","text":"Component Responsibility QR Code Data Retrieval SLAM Surface Detection User Selection 3D Rendering <p>\u26a0\ufe0f The pizza does NOT appear on the QR marker. The QR only triggers data loading.</p>"},{"location":"blog/2026-02-13-system-flow/#marker-detection-tracking-module-qr-based","title":"\ud83d\udcf7 Marker Detection &amp; Tracking Module (QR-Based)","text":""},{"location":"blog/2026-02-13-system-flow/#1-camera-frame-acquisition","title":"1\ufe0f\u20e3 Camera Frame Acquisition","text":"<p>The mobile camera continuously captures frames (30\u201360 FPS).</p> <p>Each frame undergoes preprocessing:</p> <ul> <li>Grayscale conversion  </li> <li>Edge detection  </li> <li>Corner detection  </li> </ul> <p>These steps prepare the frame for feature extraction.</p>"},{"location":"blog/2026-02-13-system-flow/#2-feature-point-extraction","title":"2\ufe0f\u20e3 Feature Point Extraction","text":"<p>AR SDKs such as:</p> <ul> <li>ARCore  </li> <li>ARKit  </li> <li>Vuforia  </li> <li>AR Foundation  </li> </ul> <p>detect distinct visual features from the QR image.</p>"},{"location":"blog/2026-02-13-system-flow/#algorithms-used-internally","title":"Algorithms Used Internally","text":"<ul> <li>ORB (Oriented FAST and Rotated BRIEF)</li> <li>FAST Corner Detection</li> <li>SIFT / SURF (legacy methods)</li> </ul> <p>These algorithms:</p> <ul> <li>Detect corners  </li> <li>Identify edges  </li> <li>Extract unique pixel patterns  </li> </ul> <p>QR codes are ideal due to:</p> <ul> <li>High black-white contrast  </li> <li>Strong geometric structure  </li> </ul> <p>Each detected feature becomes a 2D coordinate in image space.</p>"},{"location":"blog/2026-02-13-system-flow/#3-feature-matching","title":"3\ufe0f\u20e3 Feature Matching","text":"<p>The system stores a reference image of the QR marker.</p> <p>During runtime:</p> <ul> <li>Live camera features   are matched with  </li> <li>Stored QR reference features  </li> </ul> <p>Using descriptor matching.</p> <p>If sufficient matches are found \u2192 Marker detected successfully.</p>"},{"location":"blog/2026-02-13-system-flow/#4-pose-estimation","title":"4\ufe0f\u20e3 Pose Estimation","text":"<p>Once detected, the system computes:</p> <ul> <li>Rotation (R)</li> <li>Translation (T)</li> </ul> <p>Using:</p> <ul> <li>Perspective-n-Point (PnP)</li> <li>Homography Matrix</li> </ul> <p>This determines:</p> <ul> <li>Position of QR in 3D space</li> <li>Orientation relative to camera</li> </ul> <p>A transformation matrix is generated, creating a virtual coordinate system.</p>"},{"location":"blog/2026-02-13-system-flow/#surface-detection-using-slam","title":"\ud83e\udde0 Surface Detection Using SLAM","text":""},{"location":"blog/2026-02-13-system-flow/#what-is-slam","title":"What is SLAM?","text":"<p>SLAM = Simultaneous Localization and Mapping</p> <p>It performs two tasks simultaneously:</p> <ol> <li>Maps the environment.</li> <li>Tracks device movement in 3D space.</li> </ol>"},{"location":"blog/2026-02-13-system-flow/#step-1-environmental-feature-tracking","title":"Step 1\ufe0f\u20e3 Environmental Feature Tracking","text":"<p>The camera detects natural feature points such as:</p> <ul> <li>Table edges</li> <li>Wood patterns</li> <li>Corners</li> <li>Texture variations</li> </ul> <p>These are environmental features \u2014 different from QR features.</p>"},{"location":"blog/2026-02-13-system-flow/#step-2-motion-tracking","title":"Step 2\ufe0f\u20e3 Motion Tracking","text":"<p>The system combines:</p> <ul> <li>Camera input</li> <li>Gyroscope</li> <li>Accelerometer</li> </ul> <p>To determine device movement in 3D space.</p>"},{"location":"blog/2026-02-13-system-flow/#step-3-point-cloud-creation","title":"Step 3\ufe0f\u20e3 Point Cloud Creation","text":"<p>Tracked feature points are converted into a sparse 3D map.</p> <p>This forms a point cloud representation of the environment.</p>"},{"location":"blog/2026-02-13-system-flow/#step-4-plane-detection","title":"Step 4\ufe0f\u20e3 Plane Detection","text":"<p>Using algorithms like RANSAC:</p> <ul> <li>Coplanar points are clustered.</li> <li>A flat surface model is fitted.</li> </ul> <p>If sufficient horizontal points exist \u2192 A plane is detected.</p> <p>Examples: - Table surface - Floor</p>"},{"location":"blog/2026-02-13-system-flow/#complete-system-flow","title":"\ud83d\udd04 Complete System Flow","text":""},{"location":"blog/2026-02-13-system-flow/#step-1-qr-scan","title":"\ud83d\udd39 Step 1 \u2014 QR Scan","text":"<ul> <li>Camera detects QR code.</li> <li>QR is decoded.</li> <li>JSON menu data is retrieved.</li> <li>Pizza list loads in UI.</li> <li>No 3D object rendered yet.</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#step-2-slam-activation","title":"\ud83d\udd39 Step 2 \u2014 SLAM Activation","text":"<ul> <li>User moves phone.</li> <li>System detects table surface.</li> <li>Plane visualization appears.</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#step-3-pizza-selection","title":"\ud83d\udd39 Step 3 \u2014 Pizza Selection","text":"<p>When user selects a pizza:</p> <ul> <li>Corresponding 3D prefab is instantiated.</li> <li>System performs a hit test.</li> <li>Object is anchored to detected plane.</li> <li>Pizza appears on the table.</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#hit-testing-object-placement-mathematical-insight","title":"\ud83c\udfaf Hit Testing &amp; Object Placement (Mathematical Insight)","text":"<p>When placing the pizza:</p> <ol> <li>User taps screen at coordinates (x, y).</li> <li>System casts a ray from camera into 3D world.</li> <li>Ray intersects detected plane.</li> <li>Intersection point is returned.</li> <li>3D object placed at that coordinate.</li> </ol>"},{"location":"blog/2026-02-13-system-flow/#ray-equation","title":"\ud83d\udcd0 Ray Equation","text":"<p>P = O + tD</p> <p>Where:</p> <ul> <li>O = Camera origin  </li> <li>D = Direction vector  </li> <li>t = Scalar  </li> </ul>"},{"location":"blog/2026-02-13-system-flow/#plane-equation","title":"\ud83d\udcd0 Plane Equation","text":"<p>Ax + By + Cz + D = 0</p> <p>Solving the ray-plane intersection provides the precise world coordinate.</p>"},{"location":"blog/2026-02-13-system-flow/#architectural-options","title":"\ud83c\udfd7 Architectural Options","text":""},{"location":"blog/2026-02-13-system-flow/#option-a-pure-marker-based","title":"Option A \u2014 Pure Marker-Based","text":"<ul> <li>Pizza appears directly on QR.</li> <li>Simpler implementation.</li> <li>Lower computational load.</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#option-b-hybrid-recommended","title":"Option B \u2014 Hybrid (Recommended)","text":"<ul> <li>QR = Data trigger only.</li> <li>SLAM = Real-world placement.</li> <li>Pizza appears on table.</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#advantages","title":"Advantages","text":"<ul> <li>More immersive</li> <li>Technically advanced</li> <li>Stronger academic value</li> <li>Better user experience</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#important-engineering-note","title":"\u26a0\ufe0f Important Engineering Note","text":"<p>If the pizza is placed relative to the table:</p> <ul> <li>The QR marker does NOT control object position.</li> <li>It only:</li> <li>Triggers data loading</li> <li>Starts AR session</li> </ul> <p>Object placement depends entirely on:</p> <ul> <li>SLAM</li> <li>Plane detection</li> <li>Hit testing</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#technical-components-used","title":"\ud83e\udde9 Technical Components Used","text":"<ul> <li>Computer Vision</li> <li>Feature Detection Algorithms</li> <li>Pose Estimation</li> <li>SLAM</li> <li>Plane Detection</li> <li>Ray Casting</li> <li>3D Rendering Engine</li> </ul>"},{"location":"blog/2026-02-13-system-flow/#conclusion","title":"\ud83d\ude80 Conclusion","text":"<p>This Hybrid AR architecture separates:</p> <p>Data Retrieval (QR) from Spatial Placement (SLAM) </p> <p>This creates a scalable, immersive, and academically robust AR system suitable for:</p> <ul> <li>Restaurant visualization systems</li> <li>Interactive AR commerce</li> <li>Educational AR applications</li> <li>Advanced HCI research projects</li> </ul>"},{"location":"blog/2026-02-14-hybrid-ar/","title":"2026 02 14 hybrid ar","text":"<p>Author: Akarsh Date: February 13, 2026  </p>"},{"location":"blog/2026-02-14-hybrid-ar/#project-overview","title":"Project Overview","text":"<p>The AR/VR Interactive Marker-Based AR Menu Browsing System is an augmented reality application designed to explore how physical restaurant menus can be enhanced through immersive, interactive digital content.  </p> <p>The project investigates the use of marker-based AR as a practical, accessible, and low-cost approach for visualizing food items in three dimensions while maintaining a clear link between the physical and digital environments.</p> <p>The primary objective of the system is to move beyond static images traditionally used in menus and instead offer users an interactive, spatially anchored browsing experience.</p> <p>By scanning a physical marker \u2014 such as a printed menu card or QR-style image \u2014 users gain access to a virtual menu where food items can be explored visually, contextually, and interactively.</p> <p>The project emphasizes:</p> <ul> <li>Usability  </li> <li>System stability  </li> <li>Meaningful interaction  </li> </ul> <p>This makes it suitable for real-world deployment as well as academic demonstration.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#system-motivation-and-design-philosophy","title":"System Motivation and Design Philosophy","text":"<p>Early iterations of the project revealed a common limitation in basic AR applications:</p> <ul> <li>Frequent re-scanning  </li> <li>Fragmented scenes  </li> <li>Interactions focused more on novelty than usability  </li> </ul> <p>Based on evaluative feedback, the system was refined to adopt a more structured and intentional interaction model.</p> <p>The revised design prioritizes three core principles:</p>"},{"location":"blog/2026-02-14-hybrid-ar/#1-scene-persistence","title":"1\ufe0f\u20e3 Scene Persistence","text":"<p>Once activated, the AR environment should remain stable and continuous.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#2-minimal-physical-effort","title":"2\ufe0f\u20e3 Minimal Physical Effort","text":"<p>Users should not be required to repeatedly scan markers.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#3-meaningful-interaction","title":"3\ufe0f\u20e3 Meaningful Interaction","text":"<p>Every interaction should serve a functional or informational purpose.</p> <p>These principles directly informed the architectural decisions made in the refined system.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#marker-based-architecture-and-scene-initialization","title":"Marker-Based Architecture and Scene Initialization","text":"<p>At the foundation of the system lies a single-marker architecture.</p> <p>Instead of assigning individual markers to each menu item, the application intentionally uses one physical marker to represent the entire menu.  </p> <p>This marker acts as a stable spatial anchor, defining the coordinate system in which all virtual content is rendered.</p> <p>When the marker is detected by the device camera:</p> <ul> <li>The application initializes a single AR scene  </li> <li>The scene loads once  </li> <li>The interaction session continues without reinitialization  </li> </ul> <p>This design:</p> <ul> <li>Minimizes tracking loss  </li> <li>Reduces user friction  </li> <li>Preserves immersion  </li> </ul> <p>Upon successful detection, a default 3D pizza model is rendered and anchored directly to the marker, establishing a clear connection between the physical menu and its digital counterpart.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#persistent-scene-navigation-and-model-management","title":"Persistent Scene Navigation and Model Management","text":"<p>A defining feature of the refined system is its persistent AR scene.</p> <p>After the initial scan:</p> <ul> <li>The user does not need to interact with the marker again  </li> <li>Navigation is handled entirely through on-screen UI controls  </li> </ul> <p>Pizza variations are explored using left and right arrow buttons.</p> <p>Each button press dynamically replaces the currently displayed pizza model with another variant.</p> <p>Importantly:</p> <ul> <li>Position remains constant  </li> <li>Orientation remains constant  </li> <li>Scale remains constant  </li> </ul> <p>Only the model changes.</p> <p>This ensures:</p> <ul> <li>Spatial consistency  </li> <li>No disorientation  </li> <li>Effective runtime asset swapping  </li> <li>Proper AR state management  </li> </ul> <p>This demonstrates how interactive AR systems can dynamically update content without resetting spatial anchors.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#ingredient-level-interaction-and-information-discovery","title":"Ingredient-Level Interaction and Information Discovery","text":"<p>To extend the experience beyond simple visualization, the system incorporates ingredient-level interaction.</p> <p>Individual toppings on the pizza model are clickable interactive elements.</p> <p>When selected:</p> <ul> <li>The topping name appears  </li> <li>A brief descriptive overlay is displayed  </li> </ul> <p>This transforms the AR menu into an exploratory interface and demonstrates object-level interaction within a marker-based AR scene.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#nutritional-information-and-ui-integration","title":"Nutritional Information and UI Integration","text":"<p>The system also includes a nutrition toggle feature.</p> <p>Users can display or hide:</p> <ul> <li>Calorie values  </li> <li>Dietary classification (e.g., vegetarian / non-vegetarian)  </li> </ul> <p>This information is accessed through a dedicated UI button.</p> <p>The toggle-based design ensures:</p> <ul> <li>The AR scene remains visually clean  </li> <li>Information is available on demand  </li> <li>Users control their level of detail  </li> </ul> <p>This reflects strong UI design principles within immersive environments.</p>"},{"location":"blog/2026-02-14-hybrid-ar/#project-outcome-and-technical-significance","title":"Project Outcome and Technical Significance","text":"<p>Through its refinements, the project evolves from a basic AR visualization into a structured interactive system.</p> <p>The final implementation demonstrates:</p> <ul> <li>A strong understanding of marker-based AR principles  </li> <li>Effective UI and AR scene integration  </li> <li>Practical state and content management  </li> <li>A user-centered immersive interaction model  </li> </ul> <p>The Interactive Marker-Based AR Menu Browsing System showcases how augmented reality can be applied in a practical, intuitive, and technically sound manner.</p> <p>Rather than functioning as a visual gimmick, the system presents AR as a meaningful interface capable of enhancing everyday experiences such as menu browsing through thoughtful interaction design.</p>"},{"location":"blog/akarsh/","title":"Blogs by Akarsh","text":"<ul> <li>System Flow of Interactive Pizza Menu</li> <li>AR/VR Interactive Marker-Based AR Menu Browsing System</li> </ul>"},{"location":"blog/srishti/","title":"Blogs by Srishti","text":""},{"location":"blog/srishti/#blog-posts","title":"Blog Posts","text":"<ul> <li>\ud83c\udf55 Interactive Marker-Based AR Pizza Menu System</li> </ul>"},{"location":"blog/suhani/","title":"Blogs by Suhani","text":"<ul> <li>From Idea to Structure: Understanding What We Actually Built</li> </ul>"}]}